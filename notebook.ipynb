{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents <a id='back'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [1. Data Overview](#data_review)\n",
    "    * [Conclusions](#data_review_conclusions)\n",
    "* [2. Splitting the Data](#splitting_data)\n",
    "* [3. Assessing Model Quality](#model_quality)\n",
    "    * [3.1 Logistic Regression](#initial_lr)\n",
    "    * [3.2 Decision Tree](#initial_dtree)\n",
    "    * [3.3 Random Forest](#initial_rf)\n",
    "* [4. Hyperparameter Tuning](#hyperparameter_tuning)\n",
    "    * [4.1 Logistic Regression](#tuning_lr)\n",
    "    * [4.2 Decision Tree](#tuning_dtree)\n",
    "    * [4.3 Random Forest](#tuning_rf)\n",
    "* [5. Sanity Check](#sanity_check)\n",
    "* [General Conclusion](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "In this project, I will train a model that can analyze consumer behavior and recommend one of the two new packages: Smart or Ultra.  For this project, the threshold for the accuracy level is 0.75. Evaluate the accuracy metric of my model using the test dataset.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "To train a model that can recommend a package based on consumer behavior with a minimum accuracy score of 0.75.\n",
    "\n",
    "\n",
    "**This project will consist of three steps:**\n",
    "\n",
    "1. Data Overview\n",
    "2. Splitting the Data\n",
    "3. Assessing Model Quality\n",
    "4. Hyperparameter Tuning\n",
    "5. Sanity Check\n",
    "\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Overview <a id='data_review'></a>\n",
    "\n",
    "The steps to be performed are as follows:\n",
    "1. Checking the number of rows and columns.\n",
    "2. Checking for missing values.\n",
    "3. Checking for duplicate data.\n",
    "4. Checking statistical information in columns with numerical data types.\n",
    "5. Checking values in columns with categorical data types.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â load library\n",
    "\n",
    "# dataset\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# scientific computing\n",
    "import numpy as np\n",
    "\n",
    "# library for models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "path = 'data/users_behavior.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Exploration: users_behavior dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking statistic information for numerical variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_ultra\n",
       "0    2229\n",
       "1     985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data composition of target column\n",
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_ultra\n",
       "0    69.352831\n",
       "1    30.647169\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data composition percentage\n",
    "df['is_ultra'].value_counts()/df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "1. There are no missing values.\n",
    "2. The data types in the columns are correct.\n",
    "3. The composition of the target data is not ideal due to an imbalance. This implies that, since the majority of the target data is 0, there is a tendency for the model to predict the value 0. This can result in poor model performance and low accuracy. To address this imbalance, techniques like upsampling (increasing the frequency of value 1) or downsampling (reducing the frequency of value 0) can be employed. However, both upsampling and downsampling might lead to the introduction of synthetic data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting the Data <a id='splitting_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be divided into:\n",
    "\n",
    "1. Training Set: This data is used to train and build the model.\n",
    "2. Validation Set: This data is used to optimize the model during its construction. It helps assess the model's ability to recognize patterns in a general sense. The validation set is also used to evaluate the accuracy of the created model. If the accuracy is not satisfactory, hyperparameter tuning can be performed.\n",
    "3. Test Set: This data is used to test the model's performance.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "df_train_valid, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Apply `random_state 42` to obtain the same results across different executions.\n",
    "df_train, df_valid = train_test_split(df_train_valid, test_size=0.25)# untuk membuat model\n",
    "\n",
    "# features and target for training dataset\n",
    "features_train = df_train.drop('is_ultra', axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# features and target for validation dataset\n",
    "features_valid = df_valid.drop('is_ultra', axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "# features and target for test dataset\n",
    "features_test = df_test.drop('is_ultra', axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(643, 4)\n",
      "(643, 4)\n"
     ]
    }
   ],
   "source": [
    "# checking row for each dataset\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assessing Model Quality <a id='model_quality'></a>\n",
    "\n",
    "without hyperparameter tuning\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression <a id='initial_lr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on training set: 0.7484439834024896\n",
      "accuracy score on validation set:  0.7682737169517885\n"
     ]
    }
   ],
   "source": [
    "initial_model_logReg = LogisticRegression()\n",
    "\n",
    "# train training set\n",
    "initial_model_logReg.fit(features_train, target_train)\n",
    "\n",
    "# predict using training set\n",
    "y_predict_train_lr = initial_model_logReg.predict(features_train)\n",
    "\n",
    "# predict using validation set\n",
    "y_predict_valid_lr = initial_model_logReg.predict(features_valid)\n",
    "\n",
    "# test accuracy score in training set\n",
    "print(\"accuracy score on training set:\", accuracy_score(target_train, y_predict_train_lr))\n",
    "# test accuracy score in validation set\n",
    "print(\"accuracy score on validation set: \", accuracy_score(target_valid, y_predict_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decision Tree <a id='initial_dtree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on training set: 1.0\n",
      "accuracy score on validation set:  0.7527216174183515\n"
     ]
    }
   ],
   "source": [
    "initial_model_dTree = DecisionTreeClassifier()\n",
    "\n",
    "# train training set\n",
    "initial_model_dTree.fit(features_train, target_train)\n",
    "\n",
    "# predict using training set\n",
    "y_predict_train_dtree = initial_model_dTree.predict(features_train)\n",
    "\n",
    "# predict using validation set\n",
    "y_predict_valid_dtree = initial_model_dTree.predict(features_valid)\n",
    "\n",
    "# test accuracy score in training set\n",
    "print(\"accuracy score on training set:\", accuracy_score(target_train, y_predict_train_dtree))\n",
    "\n",
    "# test accuracy score in validation set\n",
    "print(\"accuracy score on validation set: \", accuracy_score(target_valid, y_predict_valid_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest <a id='initial_rf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on training set: 1.0\n",
      "accuracy score on validation set: 0.8055987558320373\n"
     ]
    }
   ],
   "source": [
    "initial_model_rf = RandomForestClassifier()\n",
    "\n",
    "# train training set\n",
    "initial_model_rf.fit(features_train, target_train)\n",
    "\n",
    "# predict using training set\n",
    "y_predict_train_rf = initial_model_rf.predict(features_train)\n",
    "\n",
    "# predict using validation set\n",
    "y_predict_valid_rf = initial_model_rf.predict(features_valid)\n",
    "\n",
    "# test accuracy score in training set\n",
    "print(\"accuracy score on training set:\", accuracy_score(target_train, y_predict_train_rf))\n",
    "# mengukur accuracy score\n",
    "print(\"accuracy score on validation set:\", accuracy_score(target_valid, y_predict_valid_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "1. Based on the training dataset, overfitting is observed. This is indicated by the accuracy value of 1.0 when using the decision tree and random forest models. This could be due to the small amount of data and the presence of imbalance.\n",
    "2. Based on the accuracy of the validation dataset,\n",
    "    - Logistic regression has the lowest accuracy rate and has not reached the threshold with an accuracy of 75% on the test dataset.\n",
    "    - Decision Tree has a moderate accuracy rate and has not reached the threshold with an accuracy of 75% on the test dataset.\n",
    "    - Random Forest has the highest accuracy rate and has already reached the 75% threshold on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Hyperparameter Tuning to Develop the model <a id='hyerparameter_tuning'></a>\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression  <a id='tuning_lr'></a>\n",
    "\n",
    "the hyperparameters that will be tuned are:\n",
    "- solver: The algorithm used for optimization. For small-sized datasets, solver: liblinear is used.\n",
    "- random_state: Controls the randomness of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the final logistic regression model, the accuracy score on the training set: 0.745850622406639\n",
      "In the final logistic regression model, the accuracy score on the validation set: 0.7620528771384136\n"
     ]
    }
   ],
   "source": [
    "final_model_lr = LogisticRegression(solver = 'liblinear', random_state = 42)\n",
    "final_model_lr.fit(features_train, target_train)\n",
    "\n",
    "# training dataset\n",
    "y_predict_train_final_lr = final_model_lr.predict(features_train)\n",
    "print(\"In the final logistic regression model, the accuracy score on the training set:\", accuracy_score(target_train, y_predict_train_final_lr))\n",
    "\n",
    "# dataset validation\n",
    "y_predict_valid_final_lr = final_model_lr.predict(features_valid)\n",
    "print(\"In the final logistic regression model, the accuracy score on the validation set:\", accuracy_score(target_valid, y_predict_valid_final_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744945567651633\n"
     ]
    }
   ],
   "source": [
    "# predict using test dataset\n",
    "y_predict_test_final_lr = final_model_lr.predict(features_test)\n",
    "\n",
    "# test accuracy score on test set\n",
    "print(accuracy_score(target_test, y_predict_test_final_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion - Logistic Regression Model**\n",
    "\n",
    "The breakdown of accuracy results before and after hyperparameter tuning is as follows:\n",
    "\n",
    "1. Training dataset --> Before: 74.8%, After: 74.5%. Decreased by 0.3%.\n",
    "2. Validation dataset --> Before: 76.8%, After: 76.2%. Decreased by 0.6%.\n",
    "3. Test dataset has an accuracy of 74.5%, which hasn't yet exceeded the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree <a id='tuning_dtree'></a>\n",
    "\n",
    "the hyperparameters that will be tuned are:\n",
    "- max_depth: Limits the number of branches, preventing overfitting if set too high.\n",
    "- random_state: Controls the randomness of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At max_depth 1 the accuracy score on validation set is 0.7682737169517885\n",
      "At max_depth 2 the accuracy score on validation set is 0.7869362363919129\n",
      "At max_depth 3 the accuracy score on validation set is 0.8180404354587869\n",
      "At max_depth 4 the accuracy score on validation set is 0.8164852255054432\n",
      "At max_depth 5 the accuracy score on validation set is 0.8164852255054432\n",
      "At max_depth 6 the accuracy score on validation set is 0.8211508553654744\n",
      "At max_depth 7 the accuracy score on validation set is 0.80248833592535\n",
      "At max_depth 8 the accuracy score on validation set is 0.8055987558320373\n",
      "At max_depth 9 the accuracy score on validation set is 0.7978227060653188\n",
      "At max_depth 10 the accuracy score on validation set is 0.8055987558320373\n",
      "At max_depth 11 the accuracy score on validation set is 0.7729393468118196\n",
      "At max_depth 12 the accuracy score on validation set is 0.7869362363919129\n",
      "At max_depth 13 the accuracy score on validation set is 0.776049766718507\n",
      "At max_depth 14 the accuracy score on validation set is 0.7682737169517885\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 15):\n",
    "    model_dtree = DecisionTreeClassifier(max_depth=depth, random_state = 42)\n",
    "    model_dtree.fit(features_train, target_train)\n",
    "    predictions_valid_dtree = model_dtree.predict(features_valid)\n",
    "    print(\"At\", \"max_depth\", depth, \"the accuracy score on validation set is \", end='')\n",
    "    print(accuracy_score(target_valid, predictions_valid_dtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the final decision tree model, the accuracy score on the training set: 0.8319502074688797\n",
      "In the final decision tree model, the accuracy score on the validation set: 0.8211508553654744\n"
     ]
    }
   ],
   "source": [
    "best_max_depth = 6\n",
    "final_model_dtree = DecisionTreeClassifier(max_depth=best_max_depth, random_state = 42)\n",
    "final_model_dtree.fit(features_train, target_train)\n",
    "\n",
    "# dataset training\n",
    "y_predict_train_final_dtree = final_model_dtree.predict(features_train)\n",
    "print(\"In the final decision tree model, the accuracy score on the training set:\", accuracy_score(target_train, y_predict_train_final_dtree))\n",
    "\n",
    "# dataset validation\n",
    "y_predict_valid_final_dtree = final_model_dtree.predict(features_valid)\n",
    "print(\"In the final decision tree model, the accuracy score on the validation set:\", accuracy_score(target_valid, y_predict_valid_final_dtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7776049766718507\n"
     ]
    }
   ],
   "source": [
    "# predict using test dataset\n",
    "y_predict_test_final_dtree = final_model_dtree.predict(features_test)\n",
    "\n",
    "# test accuracy score on test set\n",
    "print(accuracy_score(target_test, y_predict_test_final_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion - Decision Tree Model**\n",
    "\n",
    "\n",
    "The breakdown of accuracy results before and after hyperparameter tuning is as follows:\n",
    "1. Training dataset -> Before: 1, After: 83.1% > No longer experiencing overfitting.\n",
    "2. Validation dataset > Before: 75.2%, After: 82.1%. Increased by 6.9%.\n",
    "3. Test dataset has an accuracy of 77.7%, which meets the threshold for accuracy.\n",
    "4. Hyperparameters that were tuned:\n",
    "    - max_depth, with a value of 4\n",
    "    - random_state, with a value of 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest <a id='tuning_rf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the hyperparameters that will be tuned are:\n",
    "- n_estimators: Controls the number of trees in the random forest model. Increasing the number of estimators tends to decrease the prediction variance. Therefore, the more trees used, the better the results obtained.\n",
    "- max_depth: Limits the number of branches.\n",
    "- random_state: Controls the randomness of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At max_depth 1 and n_estimators 100 the accuracy score on validation set is 0.7651632970451011\n",
      "At max_depth 1 and n_estimators 200 the accuracy score on validation set is 0.7682737169517885\n",
      "At max_depth 1 and n_estimators 300 the accuracy score on validation set is 0.7667185069984448\n",
      "At max_depth 1 and n_estimators 400 the accuracy score on validation set is 0.7667185069984448\n",
      "At max_depth 1 and n_estimators 500 the accuracy score on validation set is 0.7667185069984448\n",
      "At max_depth 2 and n_estimators 100 the accuracy score on validation set is 0.8009331259720062\n",
      "At max_depth 2 and n_estimators 200 the accuracy score on validation set is 0.80248833592535\n",
      "At max_depth 2 and n_estimators 300 the accuracy score on validation set is 0.8009331259720062\n",
      "At max_depth 2 and n_estimators 400 the accuracy score on validation set is 0.8009331259720062\n",
      "At max_depth 2 and n_estimators 500 the accuracy score on validation set is 0.80248833592535\n",
      "At max_depth 3 and n_estimators 100 the accuracy score on validation set is 0.8118195956454122\n",
      "At max_depth 3 and n_estimators 200 the accuracy score on validation set is 0.8149300155520995\n",
      "At max_depth 3 and n_estimators 300 the accuracy score on validation set is 0.8133748055987559\n",
      "At max_depth 3 and n_estimators 400 the accuracy score on validation set is 0.8133748055987559\n",
      "At max_depth 3 and n_estimators 500 the accuracy score on validation set is 0.8118195956454122\n",
      "At max_depth 4 and n_estimators 100 the accuracy score on validation set is 0.8195956454121306\n",
      "At max_depth 4 and n_estimators 200 the accuracy score on validation set is 0.8180404354587869\n",
      "At max_depth 4 and n_estimators 300 the accuracy score on validation set is 0.8180404354587869\n",
      "At max_depth 4 and n_estimators 400 the accuracy score on validation set is 0.8180404354587869\n",
      "At max_depth 4 and n_estimators 500 the accuracy score on validation set is 0.8180404354587869\n",
      "At max_depth 5 and n_estimators 100 the accuracy score on validation set is 0.8195956454121306\n",
      "At max_depth 5 and n_estimators 200 the accuracy score on validation set is 0.8195956454121306\n",
      "At max_depth 5 and n_estimators 300 the accuracy score on validation set is 0.8195956454121306\n",
      "At max_depth 5 and n_estimators 400 the accuracy score on validation set is 0.8195956454121306\n",
      "At max_depth 5 and n_estimators 500 the accuracy score on validation set is 0.8195956454121306\n",
      "At max_depth 6 and n_estimators 100 the accuracy score on validation set is 0.8258164852255054\n",
      "At max_depth 6 and n_estimators 200 the accuracy score on validation set is 0.8273716951788491\n",
      "At max_depth 6 and n_estimators 300 the accuracy score on validation set is 0.8273716951788491\n",
      "At max_depth 6 and n_estimators 400 the accuracy score on validation set is 0.8289269051321928\n",
      "At max_depth 6 and n_estimators 500 the accuracy score on validation set is 0.8273716951788491\n",
      "At max_depth 7 and n_estimators 100 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 7 and n_estimators 200 the accuracy score on validation set is 0.8289269051321928\n",
      "At max_depth 7 and n_estimators 300 the accuracy score on validation set is 0.8289269051321928\n",
      "At max_depth 7 and n_estimators 400 the accuracy score on validation set is 0.8289269051321928\n",
      "At max_depth 7 and n_estimators 500 the accuracy score on validation set is 0.8304821150855366\n",
      "At max_depth 8 and n_estimators 100 the accuracy score on validation set is 0.8289269051321928\n",
      "At max_depth 8 and n_estimators 200 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 8 and n_estimators 300 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 8 and n_estimators 400 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 8 and n_estimators 500 the accuracy score on validation set is 0.8351477449455676\n",
      "At max_depth 9 and n_estimators 100 the accuracy score on validation set is 0.8398133748055988\n",
      "At max_depth 9 and n_estimators 200 the accuracy score on validation set is 0.8413685847589425\n",
      "At max_depth 9 and n_estimators 300 the accuracy score on validation set is 0.8413685847589425\n",
      "At max_depth 9 and n_estimators 400 the accuracy score on validation set is 0.8413685847589425\n",
      "At max_depth 9 and n_estimators 500 the accuracy score on validation set is 0.8398133748055988\n",
      "At max_depth 10 and n_estimators 100 the accuracy score on validation set is 0.8398133748055988\n",
      "At max_depth 10 and n_estimators 200 the accuracy score on validation set is 0.8398133748055988\n",
      "At max_depth 10 and n_estimators 300 the accuracy score on validation set is 0.838258164852255\n",
      "At max_depth 10 and n_estimators 400 the accuracy score on validation set is 0.838258164852255\n",
      "At max_depth 10 and n_estimators 500 the accuracy score on validation set is 0.8413685847589425\n",
      "At max_depth 11 and n_estimators 100 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 11 and n_estimators 200 the accuracy score on validation set is 0.838258164852255\n",
      "At max_depth 11 and n_estimators 300 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 11 and n_estimators 400 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 11 and n_estimators 500 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 12 and n_estimators 100 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 12 and n_estimators 200 the accuracy score on validation set is 0.838258164852255\n",
      "At max_depth 12 and n_estimators 300 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 12 and n_estimators 400 the accuracy score on validation set is 0.8351477449455676\n",
      "At max_depth 12 and n_estimators 500 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 13 and n_estimators 100 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 13 and n_estimators 200 the accuracy score on validation set is 0.8304821150855366\n",
      "At max_depth 13 and n_estimators 300 the accuracy score on validation set is 0.8304821150855366\n",
      "At max_depth 13 and n_estimators 400 the accuracy score on validation set is 0.8304821150855366\n",
      "At max_depth 13 and n_estimators 500 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 14 and n_estimators 100 the accuracy score on validation set is 0.8273716951788491\n",
      "At max_depth 14 and n_estimators 200 the accuracy score on validation set is 0.8258164852255054\n",
      "At max_depth 14 and n_estimators 300 the accuracy score on validation set is 0.833592534992224\n",
      "At max_depth 14 and n_estimators 400 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 14 and n_estimators 500 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 15 and n_estimators 100 the accuracy score on validation set is 0.8273716951788491\n",
      "At max_depth 15 and n_estimators 200 the accuracy score on validation set is 0.8351477449455676\n",
      "At max_depth 15 and n_estimators 300 the accuracy score on validation set is 0.8320373250388803\n",
      "At max_depth 15 and n_estimators 400 the accuracy score on validation set is 0.8304821150855366\n",
      "At max_depth 15 and n_estimators 500 the accuracy score on validation set is 0.833592534992224\n"
     ]
    }
   ],
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "n_estimator_list = [100, 200, 300, 400, 500]\n",
    "\n",
    "for depth in max_depth_list:\n",
    "    for est in n_estimator_list:\n",
    "        model_rf = RandomForestClassifier(max_depth=depth, n_estimators = est, random_state = 42)\n",
    "        model_rf.fit(features_train, target_train)\n",
    "        predictions_valid_rf = model_rf.predict(features_valid)\n",
    "        print(\"At\", \"max_depth\", depth, \"and n_estimators\", est, \"the accuracy score on validation set is \", end='')\n",
    "        print(accuracy_score(target_valid, predictions_valid_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the final random forest model, the accuracy score on the training set: 0.8848547717842323\n",
      "In the final random forest model, the accuracy score on the validation set: 0.8413685847589425\n"
     ]
    }
   ],
   "source": [
    "# dataset validation\n",
    "best_max_depth_rf = 9\n",
    "best_est = 200\n",
    "final_model_rf = RandomForestClassifier(max_depth=best_max_depth_rf, n_estimators = best_est,random_state = 42)\n",
    "final_model_rf.fit(features_train, target_train)\n",
    "\n",
    "# dataset training\n",
    "y_predict_train_final_rf = final_model_rf.predict(features_train)\n",
    "print(\"In the final random forest model, the accuracy score on the training set:\", accuracy_score(target_train, y_predict_train_final_rf))\n",
    "\n",
    "# dataset validation\n",
    "y_predict_valid_final_rf = final_model_rf.predict(features_valid)\n",
    "print(\"In the final random forest model, the accuracy score on the validation set:\", accuracy_score(target_valid, y_predict_valid_final_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055987558320373\n"
     ]
    }
   ],
   "source": [
    "# predict using test dataset\n",
    "y_predict_test_final_rf = final_model_rf.predict(features_test)\n",
    "# test accuracy score on test set\n",
    "print(accuracy_score(target_test, y_predict_test_final_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion - Random Forest Model**\n",
    "\n",
    "The breakdown of accuracy results before and after hyperparameter tuning for the Random Forest model is as follows:\n",
    "\n",
    "1. Training dataset > Before: 1, After: 88.4%. No longer experiencing overfitting.\n",
    "2. Validation dataset > Before: 80%, After: 84%. Increased by 4%.\n",
    "3. Test dataset has an accuracy of 80.5%, exceeding the threshold.\n",
    "4. Hyperparameters that were tuned:\n",
    "    - max_depth, with a value of 7\n",
    "    - n_estimators, with a value of 500\n",
    "    - random_state, with a value of 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sanity Check <a id='sanity_check'></a>\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_ultra\n",
       "0    69.352831\n",
       "1    30.647169\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check composition data of target feature (in percentage)\n",
    "df['is_ultra'].value_counts()/df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Based on the above sanity check, the model is dominated by 0. Therefore, the results are not satisfactory, at around 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Conclusion <a id='end'></a>\n",
    "\n",
    "The accuracy values for each final model after hyperparameter tuning are as follows:\n",
    "\n",
    "1. Logistic Regression: \n",
    "   - Training set: 0.745850622406639\n",
    "   - Validation set: 0.7620528771384136\n",
    "   - Test set: 0.744945567651633\n",
    "\n",
    "2. Decision Tree:\n",
    "   - Training set: 0.8319502074688797\n",
    "   - Validation set: 0.8211508553654744\n",
    "   - Test set: 0.7776049766718507\n",
    "\n",
    "3. Random Forest:\n",
    "   - Training set: 0.8848547717842323\n",
    "   - Validation set: 0.8413685847589425\n",
    "   - Test set: 0.8055987558320373\n",
    "\n",
    "Among the three models, the highest accuracy on the test set is achieved by the Random Forest model. The difference between the training set, validation set, and test set accuracy is also not substantial, indicating that overfitting is not a concern.\n",
    "\n",
    "Therefore, I would recommend the client to use the **Random Forest model** to determine the appropriate package choice between \"Smart\" and \"Ultra\".\n",
    "\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
